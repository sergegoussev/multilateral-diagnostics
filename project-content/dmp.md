# Data Management Plan

This Data Management Plan (DMP) outlines the strategies and practices for managing the data used as input for this research, data generated during the course of the project, and how the research compendium will be managed. It is inspired by [the Turing Way guidance on the topic](https://the-turing-way.netlify.app/reproducible-research/data/data-management) and [DMP assistant templates](https://dmp-pgd.ca/public_templates).

## 1. Roles and Responsibilities

The full research team is responsible for data management equally.

## 2. Input data

### Input data used by the project

Open datasets will be used for all analysis in this project. No new data will be collected. Specifically:

-   [NZ Electronics scanner dataset](https://rdrr.io/cran/multilateral/man/synthetic_gfk.html). The dataset is a modified version of a synthetic dataset.

-   [Dominiks Finer Foods dataset](https://un-task-team-for-scanner-data.github.io/price-stats-data-catalogue/dominiks.html). The raw data will be downloaded from the Chicago Booth School site for the categories of interest.

-   TBC. A third dataset may be used.

### Storage, publishing, and orchestration scripts that modify the data

Input data for the project will be stored in the `data/raw/` (raw version) or `data/clean/` (cleaned version) folder but ignored. All procesing scripts to process it and render it for anlytical output will be stored in the `src/` folder. Download scripts from sources are saved in the `src/` folder as well. In essense -- original data will not be stored in any way.

```         
├── data                    # Placeholder folders for the data
│   ├── raw                 # For raw open data
│   └── clean               # For cleaned datasets that can be used for downstream analysis
```

All orchestration scripts that modify the data will be stored in the `src/` folder. Their logic and order will be versioned.[^1] Note -- all the data for these datasets is in open formats. Interim datasets the compedium creates will leverage the `parquet` open format.

[^1]: Note – this task is TBD for now, to be completed in \[#5\](<https://github.com/sergegoussev/multilateral-diagnostics/issues/5>).

## 3. Output data

Data generated by the project will be stored in `output/tables/` folder.

## 4. Sharing, reuse, and preservation

### Mutable version of the compendium

Output data and the research compendium will stay live in its mutable form on GitHub. 

### Immutable snapshots of the compendium 

A snapshot will be taken as part of each paper that will be presented at a conference with a GitHub tag affiliated with it. Zenodo will be used to archive the snapshots with a DOI created for each snapshot. This will ensure storage and sharing of each paper alongside its research compendium going forward.

### Licenses 

Section TBC

## 5. Cost

Only open-source tools are used by this project. 